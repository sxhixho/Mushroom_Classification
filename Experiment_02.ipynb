{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Mushroom Classification** - Selecting only features with absolute correlation > 0.5"
      ],
      "metadata": {
        "id": "v-BY5QQScnRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**-Without GridSearchCV Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "qWl3RcJHeK9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import libraries, load dataset and handle missing data"
      ],
      "metadata": {
        "id": "tFgRuOXFczX5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSzI0oVzOPQg",
        "outputId": "b38c3250-b005-4f40-8165-a69808479d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-40268bc0c1d3>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Handle missing values by replacing '?' with NaN and filling with mode\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Encode categorical features"
      ],
      "metadata": {
        "id": "VLBps1Enc3tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode all categorical features using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.iloc[:, 1:]  # All columns except the first one as features\n",
        "y = df.iloc[:, 0]   # The first column as the target"
      ],
      "metadata": {
        "id": "TDf5_-zlc5ij"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Select features with absolute correlation > 0.5"
      ],
      "metadata": {
        "id": "JY40GVQ6c52D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation of features with the target\n",
        "correlation_matrix = df.corr()\n",
        "correlation_with_target = correlation_matrix.iloc[0, 1:]  # Correlation of all features with the target\n",
        "print(\"\\nCorrelation of features with the target:\")\n",
        "print(correlation_with_target)\n",
        "\n",
        "# Select features with absolute correlation > 0.5\n",
        "threshold = 0.5\n",
        "selected_features = correlation_with_target[abs(correlation_with_target) > threshold].index\n",
        "print(f\"\\nFeatures selected based on threshold ({threshold}): {list(selected_features)}\")\n",
        "\n",
        "# Retain only the selected features\n",
        "X = X[selected_features]\n",
        "print(f\"\\nShape of dataset after feature selection: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0mS2qyKc8pg",
        "outputId": "755b4af1-85b2-4a59-b5eb-58b81ece61b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation of features with the target:\n",
            "1     0.052951\n",
            "2     0.178446\n",
            "3    -0.031384\n",
            "4    -0.501530\n",
            "5    -0.093552\n",
            "6     0.129200\n",
            "7    -0.348387\n",
            "8     0.540024\n",
            "9    -0.530566\n",
            "10   -0.102019\n",
            "11   -0.324194\n",
            "12   -0.334593\n",
            "13   -0.298801\n",
            "14   -0.154003\n",
            "15   -0.146730\n",
            "16         NaN\n",
            "17    0.145142\n",
            "18   -0.214366\n",
            "19   -0.411771\n",
            "20    0.171961\n",
            "21    0.298686\n",
            "22    0.217179\n",
            "Name: 0, dtype: float64\n",
            "\n",
            "Features selected based on threshold (0.5): [4, 8, 9]\n",
            "\n",
            "Shape of dataset after feature selection: (8124, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "A1vBI-jWdPig"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Initialize the models"
      ],
      "metadata": {
        "id": "zsQ1EheRdUiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=33, n_estimators=100),\n",
        "    'SVM': SVC(),\n",
        "    'SGD': SGDClassifier(max_iter=1000, tol=1e-3)\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to store accuracies\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}"
      ],
      "metadata": {
        "id": "2aSGoUE7dVPg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Train and evaluate each model"
      ],
      "metadata": {
        "id": "X79bY-gFdcrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Training and testing accuracy\n",
        "    train_accuracies[name] = accuracy_score(y_train, model.predict(X_train))\n",
        "    test_accuracies[name] = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "    # Metrics\n",
        "    print(f\"\\n{name} Report:\")\n",
        "    print(classification_report(y_test, model.predict(X_test)))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRDkOOe-ddC4",
        "outputId": "06e7d217-cfd8-495c-d1e7-77f45631ff72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "\n",
            "Logistic Regression Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       843\n",
            "           1       0.78      0.78      0.78       782\n",
            "\n",
            "    accuracy                           0.79      1625\n",
            "   macro avg       0.79      0.79      0.79      1625\n",
            "weighted avg       0.79      0.79      0.79      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[673 170]\n",
            " [171 611]]\n",
            "\n",
            "Training Decision Tree...\n",
            "\n",
            "Decision Tree Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.81      0.86       843\n",
            "           1       0.82      0.92      0.87       782\n",
            "\n",
            "    accuracy                           0.87      1625\n",
            "   macro avg       0.87      0.87      0.87      1625\n",
            "weighted avg       0.87      0.87      0.87      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[684 159]\n",
            " [ 60 722]]\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "Random Forest Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.81      0.86       843\n",
            "           1       0.82      0.92      0.87       782\n",
            "\n",
            "    accuracy                           0.87      1625\n",
            "   macro avg       0.87      0.87      0.87      1625\n",
            "weighted avg       0.87      0.87      0.87      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[684 159]\n",
            " [ 60 722]]\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "SVM Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.89      0.81       843\n",
            "           1       0.85      0.68      0.75       782\n",
            "\n",
            "    accuracy                           0.79      1625\n",
            "   macro avg       0.80      0.78      0.78      1625\n",
            "weighted avg       0.80      0.79      0.78      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[751  92]\n",
            " [253 529]]\n",
            "\n",
            "Training SGD...\n",
            "\n",
            "SGD Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.67      0.73       843\n",
            "           1       0.70      0.83      0.76       782\n",
            "\n",
            "    accuracy                           0.75      1625\n",
            "   macro avg       0.75      0.75      0.74      1625\n",
            "weighted avg       0.75      0.75      0.74      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[564 279]\n",
            " [135 647]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Print all accuracies"
      ],
      "metadata": {
        "id": "toa7-4Ftdj0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all accuracies\n",
        "print(\"\\nModel Accuracies:\")\n",
        "for model in train_accuracies.keys():\n",
        "    print(f\"{model} - Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "print(\"\\nOverfitting Check:\")\n",
        "for model in train_accuracies.keys():\n",
        "    if train_accuracies[model] > test_accuracies[model] + 0.05:  # Threshold for overfitting\n",
        "        print(f\"{model} might be overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "    else:\n",
        "        print(f\"{model} is not overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAYc5Gt8dkVG",
        "outputId": "8d923ca0-b936-4eb7-911e-12e004f62d86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression - Training Accuracy: 0.8007, Testing Accuracy: 0.7902\n",
            "Decision Tree - Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "Random Forest - Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "SVM - Training Accuracy: 0.8001, Testing Accuracy: 0.7877\n",
            "SGD - Training Accuracy: 0.7507, Testing Accuracy: 0.7452\n",
            "\n",
            "Overfitting Check:\n",
            "Logistic Regression is not overfitting. Training Accuracy: 0.8007, Testing Accuracy: 0.7902\n",
            "Decision Tree is not overfitting. Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "Random Forest is not overfitting. Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "SVM is not overfitting. Training Accuracy: 0.8001, Testing Accuracy: 0.7877\n",
            "SGD is not overfitting. Training Accuracy: 0.7507, Testing Accuracy: 0.7452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**-With GridSearchCV Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "xuP3QIqueSf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import libraries, load dataset and handle missing data"
      ],
      "metadata": {
        "id": "wh_hmB9jeUe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Handle missing values by replacing '?' with NaN and filling with mode\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQlosL6lO7c9",
        "outputId": "e8cb88d4-0858-46ba-e0bb-689116da8a0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-07da33c9bf71>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Encode categorical features"
      ],
      "metadata": {
        "id": "S6W-Fq6Zcj3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode all categorical features using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.iloc[:, 1:]  # All columns except the first one as features\n",
        "y = df.iloc[:, 0]   # The first column as the target"
      ],
      "metadata": {
        "id": "QFkHfyZwO8th"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Select features with absolute correlation > 0.5"
      ],
      "metadata": {
        "id": "zDVDiT1TedV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation of features with the target\n",
        "correlation_matrix = df.corr()\n",
        "correlation_with_target = correlation_matrix.iloc[0, 1:]  # Correlation of all features with the target\n",
        "print(\"\\nCorrelation of features with the target:\")\n",
        "print(correlation_with_target)\n",
        "\n",
        "# Select features with absolute correlation > 0.5\n",
        "threshold = 0.5\n",
        "selected_features = correlation_with_target[abs(correlation_with_target) > threshold].index\n",
        "print(f\"\\nFeatures selected based on threshold ({threshold}): {list(selected_features)}\")\n",
        "\n",
        "# Retain only the selected features\n",
        "X = X[selected_features]\n",
        "print(f\"\\nShape of dataset after feature selection: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tzMZicPeoQF",
        "outputId": "47ae1421-9e65-4ca2-a4a1-6022310efdd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation of features with the target:\n",
            "1     0.052951\n",
            "2     0.178446\n",
            "3    -0.031384\n",
            "4    -0.501530\n",
            "5    -0.093552\n",
            "6     0.129200\n",
            "7    -0.348387\n",
            "8     0.540024\n",
            "9    -0.530566\n",
            "10   -0.102019\n",
            "11   -0.324194\n",
            "12   -0.334593\n",
            "13   -0.298801\n",
            "14   -0.154003\n",
            "15   -0.146730\n",
            "16         NaN\n",
            "17    0.145142\n",
            "18   -0.214366\n",
            "19   -0.411771\n",
            "20    0.171961\n",
            "21    0.298686\n",
            "22    0.217179\n",
            "Name: 0, dtype: float64\n",
            "\n",
            "Features selected based on threshold (0.5): [4, 8, 9]\n",
            "\n",
            "Shape of dataset after feature selection: (8124, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5DKbFwI7e-8l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Define the models' parameter grids for GridSearchCV"
      ],
      "metadata": {
        "id": "1et1MtPWe_4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models and their parameter grids for GridSearchCV\n",
        "models = {\n",
        "    'Logistic Regression': (\n",
        "        LogisticRegression(max_iter=1000),\n",
        "        {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
        "    ),\n",
        "    'Decision Tree': (\n",
        "        DecisionTreeClassifier(),\n",
        "        {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
        "    ),\n",
        "    'Random Forest': (\n",
        "        RandomForestClassifier(random_state=33),\n",
        "        {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20]}\n",
        "    ),\n",
        "    'SVM': (\n",
        "        SVC(),\n",
        "        {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "    ),\n",
        "    'SGD': (\n",
        "        SGDClassifier(max_iter=1000, tol=1e-3),\n",
        "        {'loss': ['hinge', 'log'], 'alpha': [0.0001, 0.001, 0.01]}\n",
        "    )\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to store accuracies\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}"
      ],
      "metadata": {
        "id": "hQhx3yxGfDfK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Apply GridSearchCV for each model"
      ],
      "metadata": {
        "id": "LzRfMrd6fEel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply GridSearchCV for each model\n",
        "for name, (model, param_grid) in models.items():\n",
        "    print(f\"\\nTraining {name} with GridSearchCV...\")\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best model from GridSearchCV\n",
        "    best_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "\n",
        "    # Training and testing accuracy\n",
        "    train_accuracies[name] = accuracy_score(y_train, best_model.predict(X_train))\n",
        "    test_accuracies[name] = accuracy_score(y_test, best_model.predict(X_test))\n",
        "\n",
        "    # Metrics\n",
        "    print(f\"\\n{name} Report:\")\n",
        "    print(classification_report(y_test, best_model.predict(X_test)))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, best_model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOHsfUJofExN",
        "outputId": "04bc2654-ba86-44dd-e053-52ef7d2fbdfa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression with GridSearchCV...\n",
            "Best parameters for Logistic Regression: {'C': 0.1, 'solver': 'lbfgs'}\n",
            "\n",
            "Logistic Regression Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       843\n",
            "           1       0.78      0.78      0.78       782\n",
            "\n",
            "    accuracy                           0.79      1625\n",
            "   macro avg       0.79      0.79      0.79      1625\n",
            "weighted avg       0.79      0.79      0.79      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[673 170]\n",
            " [171 611]]\n",
            "\n",
            "Training Decision Tree with GridSearchCV...\n",
            "Best parameters for Decision Tree: {'max_depth': None, 'min_samples_split': 2}\n",
            "\n",
            "Decision Tree Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.81      0.86       843\n",
            "           1       0.82      0.92      0.87       782\n",
            "\n",
            "    accuracy                           0.87      1625\n",
            "   macro avg       0.87      0.87      0.87      1625\n",
            "weighted avg       0.87      0.87      0.87      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[684 159]\n",
            " [ 60 722]]\n",
            "\n",
            "Training Random Forest with GridSearchCV...\n",
            "Best parameters for Random Forest: {'max_depth': None, 'n_estimators': 50}\n",
            "\n",
            "Random Forest Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.81      0.86       843\n",
            "           1       0.82      0.92      0.87       782\n",
            "\n",
            "    accuracy                           0.87      1625\n",
            "   macro avg       0.87      0.87      0.87      1625\n",
            "weighted avg       0.87      0.87      0.87      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[684 159]\n",
            " [ 60 722]]\n",
            "\n",
            "Training SVM with GridSearchCV...\n",
            "Best parameters for SVM: {'C': 0.1, 'kernel': 'rbf'}\n",
            "\n",
            "SVM Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       843\n",
            "           1       0.83      0.80      0.81       782\n",
            "\n",
            "    accuracy                           0.82      1625\n",
            "   macro avg       0.82      0.82      0.82      1625\n",
            "weighted avg       0.82      0.82      0.82      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[712 131]\n",
            " [155 627]]\n",
            "\n",
            "Training SGD with GridSearchCV...\n",
            "Best parameters for SGD: {'alpha': 0.0001, 'loss': 'hinge'}\n",
            "\n",
            "SGD Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.91      0.79       843\n",
            "           1       0.85      0.56      0.67       782\n",
            "\n",
            "    accuracy                           0.74      1625\n",
            "   macro avg       0.77      0.73      0.73      1625\n",
            "weighted avg       0.77      0.74      0.73      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[769  74]\n",
            " [347 435]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "15 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "7 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'epsilon_insensitive', 'huber', 'squared_epsilon_insensitive', 'hinge', 'squared_error', 'log_loss', 'squared_hinge'}. Got 'log' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "8 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'modified_huber', 'squared_error', 'squared_hinge'}. Got 'log' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.76165465        nan 0.76011618        nan 0.76011618        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Print all accuracies"
      ],
      "metadata": {
        "id": "k32c98Z7fHyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all accuracies\n",
        "print(\"\\nModel Accuracies:\")\n",
        "for model in train_accuracies.keys():\n",
        "    print(f\"{model} - Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "print(\"\\nOverfitting Check:\")\n",
        "for model in train_accuracies.keys():\n",
        "    if train_accuracies[model] > test_accuracies[model] + 0.05:  # Threshold for overfitting\n",
        "        print(f\"{model} might be overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "    else:\n",
        "        print(f\"{model} is not overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTANsW81fH7n",
        "outputId": "89814f3f-6271-4a91-e49a-f119e36e2993"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression - Training Accuracy: 0.8007, Testing Accuracy: 0.7902\n",
            "Decision Tree - Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "Random Forest - Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "SVM - Training Accuracy: 0.8280, Testing Accuracy: 0.8240\n",
            "SGD - Training Accuracy: 0.7601, Testing Accuracy: 0.7409\n",
            "\n",
            "Overfitting Check:\n",
            "Logistic Regression is not overfitting. Training Accuracy: 0.8007, Testing Accuracy: 0.7902\n",
            "Decision Tree is not overfitting. Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "Random Forest is not overfitting. Training Accuracy: 0.8675, Testing Accuracy: 0.8652\n",
            "SVM is not overfitting. Training Accuracy: 0.8280, Testing Accuracy: 0.8240\n",
            "SGD is not overfitting. Training Accuracy: 0.7601, Testing Accuracy: 0.7409\n"
          ]
        }
      ]
    }
  ]
}
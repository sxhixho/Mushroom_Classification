{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Mushroom Classification** - Excluding the feature with the highest absolute correlation"
      ],
      "metadata": {
        "id": "TV10awILU_EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**-Without GridSearchCV Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "7VgMZM1MXHfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import libraries, load dataset and handle missing data"
      ],
      "metadata": {
        "id": "s1UaC8TqVS_q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ML2cKgklge6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919a4297-377d-4356-e93f-6ec89930d0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-5ddd3282046f>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Handle missing values by replacing '?' with NaN and filling with mode\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Encode categorical features"
      ],
      "metadata": {
        "id": "dxyaJbyCVoBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode all categorical features using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.iloc[:, 1:]  # All columns except the first one as features\n",
        "y = df.iloc[:, 0]   # The first column as the target"
      ],
      "metadata": {
        "id": "eXwDjDYMVsRR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Drop the feature with the highest absolute correlation"
      ],
      "metadata": {
        "id": "kzL8I2BqV20J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation of features with the target\n",
        "correlation_matrix = df.corr()\n",
        "correlation_with_target = correlation_matrix.iloc[0, 1:]  # Correlation of all features with the target\n",
        "print(\"\\nCorrelation of features with the target:\")\n",
        "print(correlation_with_target)\n",
        "\n",
        "# Identify the feature with the highest absolute correlation\n",
        "highest_correlation_feature = correlation_with_target.abs().idxmax()\n",
        "print(f\"\\nFeature with the highest absolute correlation: {highest_correlation_feature}\")\n",
        "\n",
        "# Drop the feature with the highest absolute correlation\n",
        "X = X.drop(columns=[highest_correlation_feature])\n",
        "print(f\"\\nShape of dataset after removing the feature '{highest_correlation_feature}': {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWxX5tR8V4Rv",
        "outputId": "059010cb-fb52-4834-b936-f5291deeb4af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation of features with the target:\n",
            "1     0.052951\n",
            "2     0.178446\n",
            "3    -0.031384\n",
            "4    -0.501530\n",
            "5    -0.093552\n",
            "6     0.129200\n",
            "7    -0.348387\n",
            "8     0.540024\n",
            "9    -0.530566\n",
            "10   -0.102019\n",
            "11   -0.324194\n",
            "12   -0.334593\n",
            "13   -0.298801\n",
            "14   -0.154003\n",
            "15   -0.146730\n",
            "16         NaN\n",
            "17    0.145142\n",
            "18   -0.214366\n",
            "19   -0.411771\n",
            "20    0.171961\n",
            "21    0.298686\n",
            "22    0.217179\n",
            "Name: 0, dtype: float64\n",
            "\n",
            "Feature with the highest absolute correlation: 8\n",
            "\n",
            "Shape of dataset after removing the feature '8': (8124, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize dictionaries to store accuracies\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}"
      ],
      "metadata": {
        "id": "RiQULnWKWH1C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Logistic Regression Model"
      ],
      "metadata": {
        "id": "rniIER1BWShf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "logistic_reg = LogisticRegression(random_state=42)\n",
        "logistic_reg.fit(X_train, y_train)\n",
        "y_pred_lr = logistic_reg.predict(X_test)\n",
        "train_accuracies['Logistic Regression'] = accuracy_score(y_train, logistic_reg.predict(X_train))\n",
        "test_accuracies['Logistic Regression'] = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"\\nLogistic Regression Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SMr_P8iWVEA",
        "outputId": "da927759-0bf2-4f48-895b-95537e3b1010"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       843\n",
            "           1       0.93      0.86      0.89       782\n",
            "\n",
            "    accuracy                           0.90      1625\n",
            "   macro avg       0.90      0.90      0.90      1625\n",
            "weighted avg       0.90      0.90      0.90      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[789  54]\n",
            " [108 674]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Decision Tree Classifier"
      ],
      "metadata": {
        "id": "dLZpRNehWWEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=24)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "train_accuracies['Decision Tree'] = accuracy_score(y_train, dt_classifier.predict(X_train))\n",
        "test_accuracies['Decision Tree'] = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"\\nDecision Tree Classifier Report:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7AOQJ_1WaFc",
        "outputId": "3002aea5-1f6e-4d73-addf-8786b2d9f936"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[843   0]\n",
            " [  0 782]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Random Forest Classifier"
      ],
      "metadata": {
        "id": "UtHpKbTRWhk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=33, n_estimators=100)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "train_accuracies['Random Forest'] = accuracy_score(y_train, rf_classifier.predict(X_train))\n",
        "test_accuracies['Random Forest'] = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"\\nRandom Forest Classifier Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm5lq6ZoWlMk",
        "outputId": "fae33f83-3936-461a-ff52-0bcc6f64c37b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[843   0]\n",
            " [  0 782]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. SVM Classifier"
      ],
      "metadata": {
        "id": "Qa30hd9JWla5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Classifier\n",
        "svm_classifier = SVC(random_state=51)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "train_accuracies['SVM'] = accuracy_score(y_train, svm_classifier.predict(X_train))\n",
        "test_accuracies['SVM'] = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"\\nSVM Classifier Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRJ-Uh4lWp4r",
        "outputId": "eaa95771-ff3f-42e8-be9f-ffbcc1245fcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[843   0]\n",
            " [  0 782]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. SGD Classifier"
      ],
      "metadata": {
        "id": "4G-8bFUWWqLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD Classifier\n",
        "sgd_classifier = SGDClassifier(random_state=77)\n",
        "sgd_classifier.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd_classifier.predict(X_test)\n",
        "train_accuracies['SGD'] = accuracy_score(y_train, sgd_classifier.predict(X_train))\n",
        "test_accuracies['SGD'] = accuracy_score(y_test, y_pred_sgd)\n",
        "print(\"\\nSGD Classifier Report:\")\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_sgd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5COhEZVWtkY",
        "outputId": "7e89c77e-e162-4bee-f1df-b6728350cd30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SGD Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91       843\n",
            "           1       0.94      0.85      0.90       782\n",
            "\n",
            "    accuracy                           0.90      1625\n",
            "   macro avg       0.91      0.90      0.90      1625\n",
            "weighted avg       0.91      0.90      0.90      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[802  41]\n",
            " [115 667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. Print all accuracies"
      ],
      "metadata": {
        "id": "4DLJCZuGW_vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all accuracies\n",
        "print(\"\\nModel Accuracies:\")\n",
        "for model in train_accuracies.keys():\n",
        "    print(f\"{model} - Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "print(\"\\nOverfitting Check:\")\n",
        "for model in train_accuracies.keys():\n",
        "    if train_accuracies[model] > test_accuracies[model] + 0.05:  # Threshold for overfitting\n",
        "        print(f\"{model} might be overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "    else:\n",
        "        print(f\"{model} is not overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaKszC2VXCTE",
        "outputId": "acb837e2-9c8c-4980-8567-9b1c54974f64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression - Training Accuracy: 0.9117, Testing Accuracy: 0.9003\n",
            "Decision Tree - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "Random Forest - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SVM - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SGD - Training Accuracy: 0.9097, Testing Accuracy: 0.9040\n",
            "\n",
            "Overfitting Check:\n",
            "Logistic Regression is not overfitting. Training Accuracy: 0.9117, Testing Accuracy: 0.9003\n",
            "Decision Tree is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "Random Forest is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SVM is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SGD is not overfitting. Training Accuracy: 0.9097, Testing Accuracy: 0.9040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**-With GridSearchCV Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "LMK5ZUdbXboa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import libraries, load dataset and handle missing data"
      ],
      "metadata": {
        "id": "VIvGpu_UXdee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Handle missing values by replacing '?' with NaN and filling with mode\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ufi-ypNeF5",
        "outputId": "bf45b15e-d5d0-4c70-ce21-9a830d432c5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-07da33c9bf71>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Encode categorical features"
      ],
      "metadata": {
        "id": "XW6ASw6NXo0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode all categorical features using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.iloc[:, 1:]  # All columns except the first one as features\n",
        "y = df.iloc[:, 0]   # The first column as the target"
      ],
      "metadata": {
        "id": "ipFeS9WJXpzk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Drop the feature with the highest absolute correlation"
      ],
      "metadata": {
        "id": "meeCiVcAXqam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation of features with the target\n",
        "correlation_matrix = df.corr()\n",
        "correlation_with_target = correlation_matrix.iloc[0, 1:]  # Correlation of all features with the target\n",
        "print(\"\\nCorrelation of features with the target:\")\n",
        "print(correlation_with_target)\n",
        "\n",
        "# Identify the feature with the highest absolute correlation\n",
        "highest_correlation_feature = correlation_with_target.abs().idxmax()\n",
        "print(f\"\\nFeature with the highest absolute correlation: {highest_correlation_feature}\")\n",
        "\n",
        "# Drop the feature with the highest absolute correlation\n",
        "X = X.drop(columns=[highest_correlation_feature])\n",
        "print(f\"\\nShape of dataset after removing the feature '{highest_correlation_feature}': {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRggTREUXuei",
        "outputId": "f6644c3c-f3cd-4f6d-c17f-e5894193994b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation of features with the target:\n",
            "1     0.052951\n",
            "2     0.178446\n",
            "3    -0.031384\n",
            "4    -0.501530\n",
            "5    -0.093552\n",
            "6     0.129200\n",
            "7    -0.348387\n",
            "8     0.540024\n",
            "9    -0.530566\n",
            "10   -0.102019\n",
            "11   -0.324194\n",
            "12   -0.334593\n",
            "13   -0.298801\n",
            "14   -0.154003\n",
            "15   -0.146730\n",
            "16         NaN\n",
            "17    0.145142\n",
            "18   -0.214366\n",
            "19   -0.411771\n",
            "20    0.171961\n",
            "21    0.298686\n",
            "22    0.217179\n",
            "Name: 0, dtype: float64\n",
            "\n",
            "Feature with the highest absolute correlation: 8\n",
            "\n",
            "Shape of dataset after removing the feature '8': (8124, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HLIjbFU-YqZp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Define the models' parameter grids for GridSearchCV"
      ],
      "metadata": {
        "id": "VMYCAw1YXyHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models and their parameter grids for GridSearchCV\n",
        "models = {\n",
        "    'Logistic Regression': (\n",
        "        LogisticRegression(max_iter=1000),\n",
        "        {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
        "    ),\n",
        "    'Decision Tree': (\n",
        "        DecisionTreeClassifier(),\n",
        "        {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
        "    ),\n",
        "    'Random Forest': (\n",
        "        RandomForestClassifier(random_state=33),\n",
        "        {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20]}\n",
        "    ),\n",
        "    'SVM': (\n",
        "        SVC(),\n",
        "        {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "    ),\n",
        "    'SGD': (\n",
        "        SGDClassifier(max_iter=1000, tol=1e-3),\n",
        "        {'loss': ['hinge', 'log'], 'alpha': [0.0001, 0.001, 0.01]}\n",
        "    )\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to store accuracies\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}"
      ],
      "metadata": {
        "id": "Ta19CT5GXy0r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Apply GridsearchCV for each model"
      ],
      "metadata": {
        "id": "RrgZV5i7Yzqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply GridSearchCV for each model\n",
        "for name, (model, param_grid) in models.items():\n",
        "    print(f\"\\nTraining {name} with GridSearchCV...\")\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best model from GridSearchCV\n",
        "    best_model = grid_search.best_estimator_\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "\n",
        "    # Training and testing accuracy\n",
        "    train_accuracies[name] = accuracy_score(y_train, best_model.predict(X_train))\n",
        "    test_accuracies[name] = accuracy_score(y_test, best_model.predict(X_test))\n",
        "\n",
        "    # Metrics\n",
        "    print(f\"\\n{name} Report:\")\n",
        "    print(classification_report(y_test, best_model.predict(X_test)))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, best_model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgWH249RY1mQ",
        "outputId": "9ff19b2c-ad18-4bc4-9bd2-87b76b2ff6eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression with GridSearchCV...\n",
            "Best parameters for Logistic Regression: {'C': 1, 'solver': 'liblinear'}\n",
            "\n",
            "Logistic Regression Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       843\n",
            "           1       0.93      0.86      0.89       782\n",
            "\n",
            "    accuracy                           0.90      1625\n",
            "   macro avg       0.90      0.90      0.90      1625\n",
            "weighted avg       0.90      0.90      0.90      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[789  54]\n",
            " [108 674]]\n",
            "\n",
            "Training Decision Tree with GridSearchCV...\n",
            "Best parameters for Decision Tree: {'max_depth': None, 'min_samples_split': 2}\n",
            "\n",
            "Decision Tree Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[843   0]\n",
            " [  0 782]]\n",
            "\n",
            "Training Random Forest with GridSearchCV...\n",
            "Best parameters for Random Forest: {'max_depth': None, 'n_estimators': 50}\n",
            "\n",
            "Random Forest Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[843   0]\n",
            " [  0 782]]\n",
            "\n",
            "Training SVM with GridSearchCV...\n",
            "Best parameters for SVM: {'C': 1, 'kernel': 'rbf'}\n",
            "\n",
            "SVM Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[843   0]\n",
            " [  0 782]]\n",
            "\n",
            "Training SGD with GridSearchCV...\n",
            "Best parameters for SGD: {'alpha': 0.0001, 'loss': 'hinge'}\n",
            "\n",
            "SGD Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.92       843\n",
            "           1       0.94      0.86      0.90       782\n",
            "\n",
            "    accuracy                           0.91      1625\n",
            "   macro avg       0.91      0.91      0.91      1625\n",
            "weighted avg       0.91      0.91      0.91      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[803  40]\n",
            " [107 675]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "15 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "7 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'modified_huber', 'hinge', 'epsilon_insensitive', 'squared_error', 'log_loss', 'squared_hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "8 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'modified_huber', 'perceptron', 'huber', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'squared_hinge', 'hinge', 'log_loss'}. Got 'log' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.91629597        nan 0.91629455        nan 0.91213987        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Print all accuracies"
      ],
      "metadata": {
        "id": "kH5bnevzY9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all accuracies\n",
        "print(\"\\nModel Accuracies:\")\n",
        "for model in train_accuracies.keys():\n",
        "    print(f\"{model} - Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "print(\"\\nOverfitting Check:\")\n",
        "for model in train_accuracies.keys():\n",
        "    if train_accuracies[model] > test_accuracies[model] + 0.05:  # Threshold for overfitting\n",
        "        print(f\"{model} might be overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "    else:\n",
        "        print(f\"{model} is not overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0VRkuCJZGEL",
        "outputId": "4585c3f0-6a94-48ca-db7e-c35c0e7cd1b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression - Training Accuracy: 0.9118, Testing Accuracy: 0.9003\n",
            "Decision Tree - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "Random Forest - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SVM - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SGD - Training Accuracy: 0.9180, Testing Accuracy: 0.9095\n",
            "\n",
            "Overfitting Check:\n",
            "Logistic Regression is not overfitting. Training Accuracy: 0.9118, Testing Accuracy: 0.9003\n",
            "Decision Tree is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "Random Forest is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SVM is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SGD is not overfitting. Training Accuracy: 0.9180, Testing Accuracy: 0.9095\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Mushroom Classification** - using One-Hot Encoding"
      ],
      "metadata": {
        "id": "FB214pmSq9KP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import libraries"
      ],
      "metadata": {
        "id": "XTXImp4riLyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "h0OovqF3iYaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Load dataset and handle missing data"
      ],
      "metadata": {
        "id": "dCSE5GsRU2gy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq5VK2KjUrIL",
        "outputId": "06e99251-c79e-400a-df26-c140420b8a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset after handling missing data:\n",
            "  0  1  2  3  4  5  6  7  8  9   ... 13 14 15 16 17 18 19 20 21 22\n",
            "0  p  x  s  n  t  p  f  c  n  k  ...  s  w  w  p  w  o  p  k  s  u\n",
            "1  e  x  s  y  t  a  f  c  b  k  ...  s  w  w  p  w  o  p  n  n  g\n",
            "2  e  b  s  w  t  l  f  c  b  n  ...  s  w  w  p  w  o  p  n  n  m\n",
            "3  p  x  y  w  t  p  f  c  n  n  ...  s  w  w  p  w  o  p  k  s  u\n",
            "4  e  x  s  g  f  n  f  w  b  k  ...  s  w  w  p  w  o  e  n  a  g\n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-3dd7fc4389b4>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset from the URL\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Replace '?' with NaN\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Fill missing values with the mode (most frequent value)\n",
        "df.iloc[:, 11].fillna(df.iloc[:, 11].mode()[0], inplace=True)\n",
        "\n",
        "# Print the first few rows of the dataset\n",
        "print(\"First few rows of the dataset after handling missing data:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Encode categorical features"
      ],
      "metadata": {
        "id": "aWJzsKeUYofe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the dataset\n",
        "df_encoded = pd.get_dummies(df, columns=df.columns, drop_first=True)\n",
        "\n",
        "# Print the first few rows after encoding\n",
        "print(\"\\nFirst few rows after one-hot encoding:\")\n",
        "print(df_encoded.head())\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_encoded.iloc[:, 1:]  # All columns except the first one as features\n",
        "y = df.iloc[:, 0]           # The first column as target (not one-hot encoded)\n",
        "\n",
        "# Initialize dictionaries to store accuracies\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZjDsjAeV2Ex",
        "outputId": "286ea74c-e5f6-431c-c66f-479a9eb3ef29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First few rows after one-hot encoding:\n",
            "     0_p    1_c    1_f    1_k    1_s    1_x    2_g    2_s    2_y    3_c  ...  \\\n",
            "0   True  False  False  False  False   True  False   True  False  False  ...   \n",
            "1  False  False  False  False  False   True  False   True  False  False  ...   \n",
            "2  False  False  False  False  False  False  False   True  False  False  ...   \n",
            "3   True  False  False  False  False   True  False  False   True  False  ...   \n",
            "4  False  False  False  False  False   True  False   True  False  False  ...   \n",
            "\n",
            "    21_n   21_s   21_v   21_y   22_g   22_l   22_m   22_p   22_u   22_w  \n",
            "0  False   True  False  False  False  False  False  False   True  False  \n",
            "1   True  False  False  False   True  False  False  False  False  False  \n",
            "2   True  False  False  False  False  False   True  False  False  False  \n",
            "3  False   True  False  False  False  False  False  False   True  False  \n",
            "4  False  False  False  False   True  False  False  False  False  False  \n",
            "\n",
            "[5 rows x 95 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Logistic Regression Model"
      ],
      "metadata": {
        "id": "rSFpwk-3ZhGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train-test split for Logistic Regression\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler_lr = StandardScaler()\n",
        "X_train_lr_scaled = scaler_lr.fit_transform(X_train_lr)\n",
        "X_test_lr_scaled = scaler_lr.transform(X_test_lr)\n",
        "\n",
        "# Apply PCA to retain 95% variance\n",
        "pca_lr = PCA(n_components=0.95)\n",
        "X_train_lr_pca = pca_lr.fit_transform(X_train_lr_scaled)\n",
        "X_test_lr_pca = pca_lr.transform(X_test_lr_scaled)\n",
        "\n",
        "# Train and predict\n",
        "logistic_reg = LogisticRegression(random_state=42)\n",
        "logistic_reg.fit(X_train_lr_pca, y_train_lr)\n",
        "y_pred_lr = logistic_reg.predict(X_test_lr_pca)\n",
        "\n",
        "# Compute accuracies\n",
        "train_accuracies['Logistic Regression'] = accuracy_score(y_train_lr, logistic_reg.predict(X_train_lr_pca))\n",
        "test_accuracies['Logistic Regression'] = accuracy_score(y_test_lr, y_pred_lr)\n",
        "\n",
        "# Metrics\n",
        "print(\"\\nLogistic Regression Report:\")\n",
        "print(classification_report(y_test_lr, y_pred_lr))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_lr, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTeLcnnvZdxc",
        "outputId": "8d09660d-9427-4c86-e23e-54d43584ce53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       843\n",
            "           p       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[843   0]\n",
            " [  0 782]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Decision Tree Classifier"
      ],
      "metadata": {
        "id": "BUy3kt0kZllK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train-test split for Decision Tree\n",
        "X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X, y, test_size=0.2, random_state=24)\n",
        "\n",
        "# Train and predict\n",
        "dt_classifier = DecisionTreeClassifier(random_state=24)\n",
        "dt_classifier.fit(X_train_dt, y_train_dt)\n",
        "y_pred_dt = dt_classifier.predict(X_test_dt)\n",
        "\n",
        "# Compute accuracies\n",
        "train_accuracies['Decision Tree'] = accuracy_score(y_train_dt, dt_classifier.predict(X_train_dt))\n",
        "test_accuracies['Decision Tree'] = accuracy_score(y_test_dt, y_pred_dt)\n",
        "\n",
        "# Metrics\n",
        "print(\"\\nDecision Tree Classifier Report:\")\n",
        "print(classification_report(y_test_dt, y_pred_dt))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_dt, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dghRrFdZoEP",
        "outputId": "4e570f26-330d-4351-f91e-afad1bd1d3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       869\n",
            "           p       1.00      1.00      1.00       756\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[869   0]\n",
            " [  0 756]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Random Forest Classifier"
      ],
      "metadata": {
        "id": "o51w4GykZpSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train-test split for Random Forest\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X, y, test_size=0.2, random_state=33)\n",
        "\n",
        "# Train and predict\n",
        "rf_classifier = RandomForestClassifier(random_state=33, n_estimators=100)\n",
        "rf_classifier.fit(X_train_rf, y_train_rf)\n",
        "y_pred_rf = rf_classifier.predict(X_test_rf)\n",
        "\n",
        "# Compute accuracies\n",
        "train_accuracies['Random Forest'] = accuracy_score(y_train_rf, rf_classifier.predict(X_train_rf))\n",
        "test_accuracies['Random Forest'] = accuracy_score(y_test_rf, y_pred_rf)\n",
        "\n",
        "# Metrics\n",
        "print(\"\\nRandom Forest Classifier Report:\")\n",
        "print(classification_report(y_test_rf, y_pred_rf))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_rf, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoV2XKyhZsmh",
        "outputId": "16a008e0-6a24-4659-b18b-84f8ee31f8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       831\n",
            "           p       1.00      1.00      1.00       794\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[831   0]\n",
            " [  0 794]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. SVM Classifier"
      ],
      "metadata": {
        "id": "m2kuuifcZuNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train-test split for SVM\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X, y, test_size=0.2, random_state=51)\n",
        "\n",
        "# Standardize features\n",
        "scaler_svm = StandardScaler()\n",
        "X_train_svm_scaled = scaler_svm.fit_transform(X_train_svm)\n",
        "X_test_svm_scaled = scaler_svm.transform(X_test_svm)\n",
        "\n",
        "# Apply PCA to retain 95% variance\n",
        "pca_svm = PCA(n_components=0.95)\n",
        "X_train_svm_pca = pca_svm.fit_transform(X_train_svm_scaled)\n",
        "X_test_svm_pca = pca_svm.transform(X_test_svm_scaled)\n",
        "\n",
        "# Train and predict\n",
        "svm_classifier = SVC(random_state=51)\n",
        "svm_classifier.fit(X_train_svm_pca, y_train_svm)\n",
        "y_pred_svm = svm_classifier.predict(X_test_svm_pca)\n",
        "\n",
        "# Compute accuracies\n",
        "train_accuracies['SVM'] = accuracy_score(y_train_svm, svm_classifier.predict(X_train_svm_pca))\n",
        "test_accuracies['SVM'] = accuracy_score(y_test_svm, y_pred_svm)\n",
        "\n",
        "# Metrics\n",
        "print(\"\\nSVM Classifier Report:\")\n",
        "print(classification_report(y_test_svm, y_pred_svm))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_svm, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pysZsCs4ZyEf",
        "outputId": "3530fdc4-a8d5-42d5-91e9-57b905c968b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       855\n",
            "           p       1.00      1.00      1.00       770\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[855   0]\n",
            " [  1 769]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. SGD Classifier"
      ],
      "metadata": {
        "id": "8VlfZLgmZzQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Train-test split for SGD\n",
        "X_train_sgd, X_test_sgd, y_train_sgd, y_test_sgd = train_test_split(X, y, test_size=0.2, random_state=77)\n",
        "\n",
        "# Standardize features\n",
        "scaler_sgd = StandardScaler()\n",
        "X_train_sgd_scaled = scaler_sgd.fit_transform(X_train_sgd)\n",
        "X_test_sgd_scaled = scaler_sgd.transform(X_test_sgd)\n",
        "\n",
        "# Apply PCA to retain 95% variance\n",
        "pca_sgd = PCA(n_components=0.95)\n",
        "X_train_sgd_pca = pca_sgd.fit_transform(X_train_sgd_scaled)\n",
        "X_test_sgd_pca = pca_sgd.transform(X_test_sgd_scaled)\n",
        "\n",
        "# Train and predict\n",
        "sgd_classifier = SGDClassifier(random_state=77)\n",
        "sgd_classifier.fit(X_train_sgd_pca, y_train_sgd)\n",
        "y_pred_sgd = sgd_classifier.predict(X_test_sgd_pca)\n",
        "\n",
        "# Compute accuracies\n",
        "train_accuracies['SGD'] = accuracy_score(y_train_sgd, sgd_classifier.predict(X_train_sgd_pca))\n",
        "test_accuracies['SGD'] = accuracy_score(y_test_sgd, y_pred_sgd)\n",
        "\n",
        "# Metrics\n",
        "print(\"\\nSGD Classifier Report:\")\n",
        "print(classification_report(y_test_sgd, y_pred_sgd))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_sgd, y_pred_sgd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW_x3dcKZ2tY",
        "outputId": "d3eee0b7-3a9c-466b-d1c8-be23d3fda6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SGD Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       868\n",
            "           p       1.00      1.00      1.00       757\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[868   0]\n",
            " [  0 757]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. Print all accuracies"
      ],
      "metadata": {
        "id": "ryi_HwARZ5RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all accuracies\n",
        "print(\"\\nModel Accuracies:\")\n",
        "for model in train_accuracies.keys():\n",
        "    print(f\"{model} - Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "print(\"\\nOverfitting Check:\")\n",
        "for model in train_accuracies.keys():\n",
        "    if train_accuracies[model] > test_accuracies[model] + 0.05:  # Arbitrary threshold for overfitting\n",
        "        print(f\"{model} might be overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n",
        "    else:\n",
        "        print(f\"{model} is not overfitting. Training Accuracy: {train_accuracies[model]:.4f}, Testing Accuracy: {test_accuracies[model]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F_YTQNqZ7oj",
        "outputId": "cf4d4697-dfb0-4186-8dad-c674c685c4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression - Training Accuracy: 0.9998, Testing Accuracy: 1.0000\n",
            "Decision Tree - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "Random Forest - Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SVM - Training Accuracy: 0.9995, Testing Accuracy: 0.9994\n",
            "SGD - Training Accuracy: 0.9997, Testing Accuracy: 1.0000\n",
            "\n",
            "Overfitting Check:\n",
            "Logistic Regression is not overfitting. Training Accuracy: 0.9998, Testing Accuracy: 1.0000\n",
            "Decision Tree is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "Random Forest is not overfitting. Training Accuracy: 1.0000, Testing Accuracy: 1.0000\n",
            "SVM is not overfitting. Training Accuracy: 0.9995, Testing Accuracy: 0.9994\n",
            "SGD is not overfitting. Training Accuracy: 0.9997, Testing Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}